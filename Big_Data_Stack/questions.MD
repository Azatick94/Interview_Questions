
HADOOP LEARNING SOURCES:
1) <a href="https://stepik.org/course/150/syllabus">Stepik Hadoop Course</a>
2) <a href="https://www.datasciencecentral.com/profiles/blogs/how-to-install-and-run-hadoop-on-windows-for-beginners">Hadoop Windows Installation Guide</a>
3) <a href="https://www.youtube.com/watch?v=g7Qpnmi0Q-s&t=197s">Youtube video installion guide</a>

Вопросы. 

---
<h2>* Из каких компонентов состоит Hadoop</h2>
* HDFS: Hadoop Distributed FileSystem (Распределенная файловая система); 
* MapReduce: Фреймворк распределенной обработки данных <br>
  Другие компоненты:<br>
* HBase: Column-oriented DB, NoSQl база данных
* Zookeeper - Координатор задач
* Oozie - диспетчер задач для Hadoop
* Pig - Язык обработки данных и среда выполнения
* Hive - Data WareHouse c SQL интерфейсом. 

---
<h2>* Особенности Hadoop</h2>
* Горизонтальное масштабирование вместо вертикального (можно увеличить кол-во машин или уменьшить в зависимости от потребности)
* Умение обрабатывать падение нод и отказы оборудования (обработка происходит за счет -Репликации данных, -Перезапуска тасков)
* Код хранится вместе с данными (К каждому серверу для хранения данных копируется код для ее обработки)
* Инкапсуляция сложности реализации (Hadoop скрывает многие сложности распределнных и многопоточных систем). 
* Быстрая скорость чтения данных

---
<h2>* Ноды в HDFS</h2>
* NameNode
* Secondary NameNode (копия)
* DataNode

NameNode - отвечает за:<br>
1) файловое пространство (namespace)
2) мета-информация
3) расположение блоков файлов

DataNode - <br>
1) Хранит и отдает блоки данных 
2) Отправляет ответы о состоянии на Namenode 
3) Запускается на каждой машине кластера

---
<h2>* Hadoop Java API</h2>
org.apache.hadoop.fs.FileSystem - абстрактный класс, который представляет абстрактную файловую систему. 

4 реализации этого абстрактного класса:
1) LocalFileSystem
2) DistributedFileSystem
3) HftpFileSystem
4) FTPFileSystem

---
<h2>* Класс Configuration в Hadoop Java Api</h2>
* Объект Configuration хранит конфигурацию сервера и клиента. 
* Это HashMap - то есть используется парагидма ключ-значение

---
<h2>* Чтение данных из файла в Hadoop через Java</h2>
* Создание объекта FileSystem
* Открытие InputStream c указанием на Path
* Далее через InputStream копируем побайтово данные 
* И закрываем InputStream.

---
<h2>* Что такое Map-Reduce</h2>
Это модель распределенных вычислений для обработки больших объемов данных. 
<br>
Map - процесс обработки данных. <br>
Reduce - операция светки данных. 

Ключевые достоинства Map-Reduce: <br>

* Возможность распределенного выполнения операций предварительной обработки (map) и свертки (reduce) большого объема данных. При этом функции map работают независимо друг от друга и могут выполняться параллельно на разных узлах кластера. Отметим, что на практике количество одновременно исполняемых функций map ограничивается источником входных данных и числом используемых процессоров. Аналогичным образом множество узлов производят свертку (reduce) после того, как каждый из них обработал все результаты функции map с одним конкретным значением ключа.
* Быстрота обработки больших объёмов данных за счет распределения операций по вышеописанному принципу. В частности, всего за пару часов MapReduce может отсортировать целый петабайт данных.
* Отказоустойчивость и оперативное восстановления после сбоев: при отказе рабочего узла, производящего операцию map или reduce, его работа автоматически передается другому рабочему узлу в случае доступности входных данных для проводимой операции.

---
<h2>* Как конфигурируется Map-Reduce задача через Java API</h2>
Класс Job

Для конфигурирования Map-Reduce задачи используется класс Job. <br>
Для инициализации задачи нужно указать следующие параметры:
* input/output пути
* формат input/output данных
* указание классов для mapper, reducer, combiner, partitioner
* типы значений пар key/value
* количество редбюсеров

---
<h2>* Hadoop Streaming</h2>
Позволяет писать Map-Reduce таски на других языках программирования помимо Java (например написание на Python)

---
<h2>* Pig. Что эта за технология.</h2>
Pig - высокоуровневая платформа поверх Hadoop. <br>
* Используется язык программирования выокого уровня Pig Latin
* Код программы преобразуется в MapReduce задачи

---
<h2>* Hive. Что эта за технология.</h2>
* Работает поверх Hadoop
* Предоставляет SQL-подобный язык (HiveQl)
* Hive Не предоставляет Low latency или realtime-запросы. 

---
<h2>* NoSQL базы данных. Особенности. Преимущества. </h2>
Решает проблему масштабируемости. <br> 
NoSQL - Not Only SQL. <br>

Особенности:
* Применение различных типов хранилищ
* Нефиксированная схема БД
* Линейная маштабируемость
* Сокращение времени разработки

HBase - (Hadoop Based DB) NoSQL БД
* Написана на Java
* Распределенная база данных 
* Column-Oriented хранилище данных

Cassandra - NoSQl БД
* Написана на Java
* Поддержка репликации
* Масштабируема 
* Устойчива к сбоям
* Поддержка MapReduce Hadoop
* SQL-подобный язык доступа к данным (CQL - Cassandra Query Language)
* Low latency - быстрый доступ к данным

---
<h2>* Spark. Что такое</h2>
Spark - это развитие MapReduce подхода. 

Преимущества Spark:
* Может работать с разными типами данных
* Может обрабатывать данные по частям (batch) и в потоке (streaming)
* Имеет 80 высокоуровневых функций для обработки данных (кроме map & reduce)